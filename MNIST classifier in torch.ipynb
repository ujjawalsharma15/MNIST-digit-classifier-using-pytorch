{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST digit classifier using CNN in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets , transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the MNIST dataset from torch.MNIST class\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=False)\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "#finding the size of the loaded data \n",
    "# 60000 -> number of images \n",
    "# 28*28 -> size of the images\n",
    "\n",
    "print(train_dataset.train_data.size())\n",
    "print(train_dataset.train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "#test_data has 10000 images\n",
    "print(test_dataset.test_data.size())\n",
    "print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2a682175f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting random images from the dataset to get know about the type of images\n",
    "\n",
    "plt.imshow(train_dataset.train_data[0].numpy(),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data into torch dataloader for training and testing\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the structure of our model, used 3 convolutional layers , with 3 ReLU and two max pools \n",
    "\n",
    "class Arch(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Arch,self).__init__()\n",
    "        self.seq_1 =  nn.Sequential(nn.Conv2d(1,8,kernel_size=3,padding=1),nn.ReLU())\n",
    "        self.seq_2 = nn.Sequential(nn.Conv2d(8,12,kernel_size=3,padding=1),nn.ReLU(),nn.MaxPool2d(2, stride=2))\n",
    "        self.seq_3 = nn.Sequential(nn.Conv2d(12,16,kernel_size=3,padding=1),nn.ReLU(),nn.MaxPool2d(2, stride=2))\n",
    "        self.fc = nn.Linear(16*7*7,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.seq_1(x)\n",
    "        x = self.seq_2(x)\n",
    "        x = self.seq_3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return nn.functional.log_softmax(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arch(\n",
      "  (seq_1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (seq_2): Sequential(\n",
      "    (0): Conv2d(8, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (seq_3): Sequential(\n",
      "    (0): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#initializing our model\n",
    "cnn = Arch()\n",
    "print(cnn)\n",
    "#to see how our strategy of decreasing the learning rate with training works..  \n",
    "loss_list = []\n",
    "lr_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defing our training function\n",
    "def train(epoch,lr,arch):\n",
    "    #optimizer used is SGD with momentum \n",
    "    optimizer = optim.SGD(cnn.parameters(),lr=lr,momentum=0.5,dampening=0.75)\n",
    "    arch.train()\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        for batch_idx,(data,label) in enumerate(train_loader):\n",
    "            data,label = Variable(data),Variable(label)\n",
    "            optimizer.zero_grad()             #after one step reinitializing the gradients to zero\n",
    "            output = arch.forward(data)       #forward pass \n",
    "            loss = nn.functional.nll_loss(output,label)  #calculating the loss\n",
    "            loss.backward()                   \n",
    "            optimizer.step()                  #updating the parameters\n",
    "            if(batch_idx%30 == 0):\n",
    "               print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(i, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.data[0]))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.291120\n",
      "Train Epoch: 0 [960/60000 (2%)]\tLoss: 1.558821\n",
      "Train Epoch: 0 [1920/60000 (3%)]\tLoss: 0.559015\n",
      "Train Epoch: 0 [2880/60000 (5%)]\tLoss: 0.512242\n",
      "Train Epoch: 0 [3840/60000 (6%)]\tLoss: 0.369250\n",
      "Train Epoch: 0 [4800/60000 (8%)]\tLoss: 0.180393\n",
      "Train Epoch: 0 [5760/60000 (10%)]\tLoss: 0.202994\n",
      "Train Epoch: 0 [6720/60000 (11%)]\tLoss: 0.221051\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 0.015287\n",
      "Train Epoch: 0 [8640/60000 (14%)]\tLoss: 0.027045\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.174384\n",
      "Train Epoch: 0 [10560/60000 (18%)]\tLoss: 0.400482\n",
      "Train Epoch: 0 [11520/60000 (19%)]\tLoss: 0.046980\n",
      "Train Epoch: 0 [12480/60000 (21%)]\tLoss: 0.085015\n",
      "Train Epoch: 0 [13440/60000 (22%)]\tLoss: 0.175087\n",
      "Train Epoch: 0 [14400/60000 (24%)]\tLoss: 0.093272\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 0.050775\n",
      "Train Epoch: 0 [16320/60000 (27%)]\tLoss: 0.157661\n",
      "Train Epoch: 0 [17280/60000 (29%)]\tLoss: 0.037356\n",
      "Train Epoch: 0 [18240/60000 (30%)]\tLoss: 0.062617\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.025220\n",
      "Train Epoch: 0 [20160/60000 (34%)]\tLoss: 0.222653\n",
      "Train Epoch: 0 [21120/60000 (35%)]\tLoss: 0.088225\n",
      "Train Epoch: 0 [22080/60000 (37%)]\tLoss: 0.052749\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 0.191976\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.238768\n",
      "Train Epoch: 0 [24960/60000 (42%)]\tLoss: 0.234098\n",
      "Train Epoch: 0 [25920/60000 (43%)]\tLoss: 0.038028\n",
      "Train Epoch: 0 [26880/60000 (45%)]\tLoss: 0.049041\n",
      "Train Epoch: 0 [27840/60000 (46%)]\tLoss: 0.110197\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.054376\n",
      "Train Epoch: 0 [29760/60000 (50%)]\tLoss: 0.376006\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 0.068395\n",
      "Train Epoch: 0 [31680/60000 (53%)]\tLoss: 0.347378\n",
      "Train Epoch: 0 [32640/60000 (54%)]\tLoss: 0.048953\n",
      "Train Epoch: 0 [33600/60000 (56%)]\tLoss: 0.089091\n",
      "Train Epoch: 0 [34560/60000 (58%)]\tLoss: 0.019524\n",
      "Train Epoch: 0 [35520/60000 (59%)]\tLoss: 0.094161\n",
      "Train Epoch: 0 [36480/60000 (61%)]\tLoss: 0.044132\n",
      "Train Epoch: 0 [37440/60000 (62%)]\tLoss: 0.233153\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.055685\n",
      "Train Epoch: 0 [39360/60000 (66%)]\tLoss: 0.105637\n",
      "Train Epoch: 0 [40320/60000 (67%)]\tLoss: 0.038169\n",
      "Train Epoch: 0 [41280/60000 (69%)]\tLoss: 0.032804\n",
      "Train Epoch: 0 [42240/60000 (70%)]\tLoss: 0.037535\n",
      "Train Epoch: 0 [43200/60000 (72%)]\tLoss: 0.004322\n",
      "Train Epoch: 0 [44160/60000 (74%)]\tLoss: 0.011658\n",
      "Train Epoch: 0 [45120/60000 (75%)]\tLoss: 0.073780\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 0.027676\n",
      "Train Epoch: 0 [47040/60000 (78%)]\tLoss: 0.009099\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.126795\n",
      "Train Epoch: 0 [48960/60000 (82%)]\tLoss: 0.169933\n",
      "Train Epoch: 0 [49920/60000 (83%)]\tLoss: 0.072373\n",
      "Train Epoch: 0 [50880/60000 (85%)]\tLoss: 0.043741\n",
      "Train Epoch: 0 [51840/60000 (86%)]\tLoss: 0.125775\n",
      "Train Epoch: 0 [52800/60000 (88%)]\tLoss: 0.227545\n",
      "Train Epoch: 0 [53760/60000 (90%)]\tLoss: 0.005714\n",
      "Train Epoch: 0 [54720/60000 (91%)]\tLoss: 0.186147\n",
      "Train Epoch: 0 [55680/60000 (93%)]\tLoss: 0.297794\n",
      "Train Epoch: 0 [56640/60000 (94%)]\tLoss: 0.035531\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.048974\n",
      "Train Epoch: 0 [58560/60000 (98%)]\tLoss: 0.001439\n",
      "Train Epoch: 0 [59520/60000 (99%)]\tLoss: 0.009577\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.155855\n",
      "Train Epoch: 1 [960/60000 (2%)]\tLoss: 0.199257\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.046947\n",
      "Train Epoch: 1 [2880/60000 (5%)]\tLoss: 0.045063\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.038721\n",
      "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 0.016390\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.020793\n",
      "Train Epoch: 1 [6720/60000 (11%)]\tLoss: 0.021708\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.034861\n",
      "Train Epoch: 1 [8640/60000 (14%)]\tLoss: 0.035627\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.034940\n",
      "Train Epoch: 1 [10560/60000 (18%)]\tLoss: 0.105665\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.215517\n",
      "Train Epoch: 1 [12480/60000 (21%)]\tLoss: 0.087202\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.091179\n",
      "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.008177\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.195768\n",
      "Train Epoch: 1 [16320/60000 (27%)]\tLoss: 0.301457\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.021485\n",
      "Train Epoch: 1 [18240/60000 (30%)]\tLoss: 0.150100\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.048019\n",
      "Train Epoch: 1 [20160/60000 (34%)]\tLoss: 0.158977\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.008676\n",
      "Train Epoch: 1 [22080/60000 (37%)]\tLoss: 0.069643\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.042601\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.006105\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.040747\n",
      "Train Epoch: 1 [25920/60000 (43%)]\tLoss: 0.022417\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.036399\n",
      "Train Epoch: 1 [27840/60000 (46%)]\tLoss: 0.086767\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.116879\n",
      "Train Epoch: 1 [29760/60000 (50%)]\tLoss: 0.350597\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.072355\n",
      "Train Epoch: 1 [31680/60000 (53%)]\tLoss: 0.008779\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.090892\n",
      "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.084332\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.077136\n",
      "Train Epoch: 1 [35520/60000 (59%)]\tLoss: 0.011604\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.014555\n",
      "Train Epoch: 1 [37440/60000 (62%)]\tLoss: 0.050913\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.063533\n",
      "Train Epoch: 1 [39360/60000 (66%)]\tLoss: 0.008502\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.090123\n",
      "Train Epoch: 1 [41280/60000 (69%)]\tLoss: 0.013698\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.221340\n",
      "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.015545\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.112554\n",
      "Train Epoch: 1 [45120/60000 (75%)]\tLoss: 0.018744\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.041010\n",
      "Train Epoch: 1 [47040/60000 (78%)]\tLoss: 0.001506\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.009598\n",
      "Train Epoch: 1 [48960/60000 (82%)]\tLoss: 0.007397\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.010643\n",
      "Train Epoch: 1 [50880/60000 (85%)]\tLoss: 0.074808\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.002477\n",
      "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.001354\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.044185\n",
      "Train Epoch: 1 [54720/60000 (91%)]\tLoss: 0.008978\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.064951\n",
      "Train Epoch: 1 [56640/60000 (94%)]\tLoss: 0.014752\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.068522\n",
      "Train Epoch: 1 [58560/60000 (98%)]\tLoss: 0.058953\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.002118\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.021281\n",
      "Train Epoch: 2 [960/60000 (2%)]\tLoss: 0.023709\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.026772\n",
      "Train Epoch: 2 [2880/60000 (5%)]\tLoss: 0.002561\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.098519\n",
      "Train Epoch: 2 [4800/60000 (8%)]\tLoss: 0.000677\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.181236\n",
      "Train Epoch: 2 [6720/60000 (11%)]\tLoss: 0.039645\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.197360\n",
      "Train Epoch: 2 [8640/60000 (14%)]\tLoss: 0.039141\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.083804\n",
      "Train Epoch: 2 [10560/60000 (18%)]\tLoss: 0.077858\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.000857\n",
      "Train Epoch: 2 [12480/60000 (21%)]\tLoss: 0.100091\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.017136\n",
      "Train Epoch: 2 [14400/60000 (24%)]\tLoss: 0.007826\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.035761\n",
      "Train Epoch: 2 [16320/60000 (27%)]\tLoss: 0.013591\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.005215\n",
      "Train Epoch: 2 [18240/60000 (30%)]\tLoss: 0.010549\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.012760\n",
      "Train Epoch: 2 [20160/60000 (34%)]\tLoss: 0.142595\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.574372\n",
      "Train Epoch: 2 [22080/60000 (37%)]\tLoss: 0.087860\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.033374\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.019993\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.216048\n",
      "Train Epoch: 2 [25920/60000 (43%)]\tLoss: 0.003144\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.007513\n",
      "Train Epoch: 2 [27840/60000 (46%)]\tLoss: 0.004064\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.012497\n",
      "Train Epoch: 2 [29760/60000 (50%)]\tLoss: 0.004732\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.173913\n",
      "Train Epoch: 2 [31680/60000 (53%)]\tLoss: 0.007542\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.032797\n",
      "Train Epoch: 2 [33600/60000 (56%)]\tLoss: 0.115569\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.107049\n",
      "Train Epoch: 2 [35520/60000 (59%)]\tLoss: 0.009479\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.013325\n",
      "Train Epoch: 2 [37440/60000 (62%)]\tLoss: 0.010361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.162310\n",
      "Train Epoch: 2 [39360/60000 (66%)]\tLoss: 0.015730\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.005924\n",
      "Train Epoch: 2 [41280/60000 (69%)]\tLoss: 0.031267\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.032028\n",
      "Train Epoch: 2 [43200/60000 (72%)]\tLoss: 0.010420\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.016495\n",
      "Train Epoch: 2 [45120/60000 (75%)]\tLoss: 0.055319\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.095686\n",
      "Train Epoch: 2 [47040/60000 (78%)]\tLoss: 0.013784\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.111004\n",
      "Train Epoch: 2 [48960/60000 (82%)]\tLoss: 0.132793\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.007125\n",
      "Train Epoch: 2 [50880/60000 (85%)]\tLoss: 0.093045\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.086077\n",
      "Train Epoch: 2 [52800/60000 (88%)]\tLoss: 0.013547\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.312774\n",
      "Train Epoch: 2 [54720/60000 (91%)]\tLoss: 0.063939\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.003406\n",
      "Train Epoch: 2 [56640/60000 (94%)]\tLoss: 0.002149\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.340876\n",
      "Train Epoch: 2 [58560/60000 (98%)]\tLoss: 0.170015\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.006204\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.292821\n",
      "Train Epoch: 3 [960/60000 (2%)]\tLoss: 0.001540\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.298588\n",
      "Train Epoch: 3 [2880/60000 (5%)]\tLoss: 0.049166\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.002096\n",
      "Train Epoch: 3 [4800/60000 (8%)]\tLoss: 0.021682\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.002477\n",
      "Train Epoch: 3 [6720/60000 (11%)]\tLoss: 0.005783\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.033674\n",
      "Train Epoch: 3 [8640/60000 (14%)]\tLoss: 0.121048\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.085110\n",
      "Train Epoch: 3 [10560/60000 (18%)]\tLoss: 0.041475\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.025971\n",
      "Train Epoch: 3 [12480/60000 (21%)]\tLoss: 0.003123\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.010354\n",
      "Train Epoch: 3 [14400/60000 (24%)]\tLoss: 0.003523\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.083453\n",
      "Train Epoch: 3 [16320/60000 (27%)]\tLoss: 0.055020\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.027104\n",
      "Train Epoch: 3 [18240/60000 (30%)]\tLoss: 0.117164\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.002004\n",
      "Train Epoch: 3 [20160/60000 (34%)]\tLoss: 0.030132\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.057266\n",
      "Train Epoch: 3 [22080/60000 (37%)]\tLoss: 0.196229\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.020366\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.025610\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.018672\n",
      "Train Epoch: 3 [25920/60000 (43%)]\tLoss: 0.022727\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.028955\n",
      "Train Epoch: 3 [27840/60000 (46%)]\tLoss: 0.001559\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.020820\n",
      "Train Epoch: 3 [29760/60000 (50%)]\tLoss: 0.032700\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.012255\n",
      "Train Epoch: 3 [31680/60000 (53%)]\tLoss: 0.000785\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.000802\n",
      "Train Epoch: 3 [33600/60000 (56%)]\tLoss: 0.000703\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.034115\n",
      "Train Epoch: 3 [35520/60000 (59%)]\tLoss: 0.143667\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.001706\n",
      "Train Epoch: 3 [37440/60000 (62%)]\tLoss: 0.014431\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.201677\n",
      "Train Epoch: 3 [39360/60000 (66%)]\tLoss: 0.038695\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.055485\n",
      "Train Epoch: 3 [41280/60000 (69%)]\tLoss: 0.170210\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.041671\n",
      "Train Epoch: 3 [43200/60000 (72%)]\tLoss: 0.001268\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.001463\n",
      "Train Epoch: 3 [45120/60000 (75%)]\tLoss: 0.003261\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.344613\n",
      "Train Epoch: 3 [47040/60000 (78%)]\tLoss: 0.057225\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.011276\n",
      "Train Epoch: 3 [48960/60000 (82%)]\tLoss: 0.001338\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.004309\n",
      "Train Epoch: 3 [50880/60000 (85%)]\tLoss: 0.012655\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.167437\n",
      "Train Epoch: 3 [52800/60000 (88%)]\tLoss: 0.000232\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.002601\n",
      "Train Epoch: 3 [54720/60000 (91%)]\tLoss: 0.009242\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.003536\n",
      "Train Epoch: 3 [56640/60000 (94%)]\tLoss: 0.006004\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.007084\n",
      "Train Epoch: 3 [58560/60000 (98%)]\tLoss: 0.012371\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.007770\n"
     ]
    }
   ],
   "source": [
    "#training our model\n",
    "train(4,0.5,cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the test function of our model\n",
    "def test(arch):\n",
    "    arch.eval()\n",
    "    test_loss = 0\n",
    "    accurate_pred = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = arch.forward(data)  #forward pass for test set\n",
    "        # sum up batch loss\n",
    "        test_loss += nn.functional.nll_loss(output, target, size_average=False).data[0]\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        accurate_pred += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, accurate_pred, len(test_loader.dataset),\n",
    "        100. * accurate_pred / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0441, Accuracy: 9847/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing the accuracy and loss of test set and also the number of classes classified correctly by the model\n",
    "test(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
