{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST digit classifier using CNN in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets , transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the MNIST dataset from torch.MNIST class\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=False)\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "#finding the size of the loaded data \n",
    "# 60000 -> number of images \n",
    "# 28*28 -> size of the images\n",
    "\n",
    "print(train_dataset.train_data.size())\n",
    "print(train_dataset.train_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n",
      "torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "#test_data has 10000 images\n",
    "print(test_dataset.test_data.size())\n",
    "print(test_dataset.test_labels.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f64ad54e6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting random images from the dataset to get know about the type of images\n",
    "\n",
    "plt.imshow(train_dataset.train_data[0].numpy(),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data into torch dataloader for training and testing\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the structure of our model, used 3 convolutional layers , with 3 ReLU and two max pools \n",
    "\n",
    "class Arch(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Arch,self).__init__()\n",
    "        self.seq_1 =  nn.Sequential(nn.Conv2d(1,8,kernel_size=3,padding=1),nn.ReLU())\n",
    "        self.seq_2 = nn.Sequential(nn.Conv2d(8,12,kernel_size=3,padding=1),nn.ReLU(),nn.MaxPool2d(2, stride=2))\n",
    "        self.seq_3 = nn.Sequential(nn.Conv2d(12,16,kernel_size=3,padding=1),nn.ReLU(),nn.MaxPool2d(2, stride=2))\n",
    "        self.fc = nn.Linear(16*7*7,10)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.seq_1(x)\n",
    "        x = self.seq_2(x)\n",
    "        x = self.seq_3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return nn.functional.log_softmax(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arch(\n",
      "  (seq_1): Sequential(\n",
      "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (seq_2): Sequential(\n",
      "    (0): Conv2d(8, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (seq_3): Sequential(\n",
      "    (0): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#initializing our model\n",
    "cnn = Arch()\n",
    "print(cnn)\n",
    "#to see how our strategy of decreasing the learning rate with training works..  \n",
    "loss_list = []\n",
    "lr_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defing our training function\n",
    "def train(epoch,lr,arch):\n",
    "    #optimizer used is SGD with momentum \n",
    "    optimizer = optim.SGD(cnn.parameters(),lr=lr,momentum=0.5,dampening=0.75)\n",
    "    arch.train()\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        for batch_idx,(data,label) in enumerate(train_loader):\n",
    "            data,label = Variable(data),Variable(label)\n",
    "            optimizer.zero_grad()             #after one step reinitializing the gradients to zero\n",
    "            output = arch.forward(data)       #forward pass \n",
    "            loss = nn.functional.nll_loss(output,label)  #calculating the loss\n",
    "            loss.backward()                   \n",
    "            optimizer.step()                  #updating the parameters\n",
    "            if(batch_idx%30 == 0):\n",
    "                lr_list.append(lr)            \n",
    "                lr = lr/2.0\n",
    "                loss_list.append(loss)\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(i, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.data[0]))          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.300476\n",
      "Train Epoch: 0 [960/60000 (2%)]\tLoss: 1.764290\n",
      "Train Epoch: 0 [1920/60000 (3%)]\tLoss: 0.103087\n",
      "Train Epoch: 0 [2880/60000 (5%)]\tLoss: 0.445618\n",
      "Train Epoch: 0 [3840/60000 (6%)]\tLoss: 0.466762\n",
      "Train Epoch: 0 [4800/60000 (8%)]\tLoss: 0.277915\n",
      "Train Epoch: 0 [5760/60000 (10%)]\tLoss: 0.172770\n",
      "Train Epoch: 0 [6720/60000 (11%)]\tLoss: 0.188242\n",
      "Train Epoch: 0 [7680/60000 (13%)]\tLoss: 0.046698\n",
      "Train Epoch: 0 [8640/60000 (14%)]\tLoss: 0.091033\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.257428\n",
      "Train Epoch: 0 [10560/60000 (18%)]\tLoss: 0.079127\n",
      "Train Epoch: 0 [11520/60000 (19%)]\tLoss: 0.091782\n",
      "Train Epoch: 0 [12480/60000 (21%)]\tLoss: 0.226366\n",
      "Train Epoch: 0 [13440/60000 (22%)]\tLoss: 0.103199\n",
      "Train Epoch: 0 [14400/60000 (24%)]\tLoss: 0.089952\n",
      "Train Epoch: 0 [15360/60000 (26%)]\tLoss: 0.025099\n",
      "Train Epoch: 0 [16320/60000 (27%)]\tLoss: 0.029311\n",
      "Train Epoch: 0 [17280/60000 (29%)]\tLoss: 0.246823\n",
      "Train Epoch: 0 [18240/60000 (30%)]\tLoss: 0.285644\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.348210\n",
      "Train Epoch: 0 [20160/60000 (34%)]\tLoss: 0.152986\n",
      "Train Epoch: 0 [21120/60000 (35%)]\tLoss: 0.037743\n",
      "Train Epoch: 0 [22080/60000 (37%)]\tLoss: 0.086162\n",
      "Train Epoch: 0 [23040/60000 (38%)]\tLoss: 0.172000\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.160117\n",
      "Train Epoch: 0 [24960/60000 (42%)]\tLoss: 0.231711\n",
      "Train Epoch: 0 [25920/60000 (43%)]\tLoss: 0.136166\n",
      "Train Epoch: 0 [26880/60000 (45%)]\tLoss: 0.095086\n",
      "Train Epoch: 0 [27840/60000 (46%)]\tLoss: 0.042745\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.146722\n",
      "Train Epoch: 0 [29760/60000 (50%)]\tLoss: 0.143425\n",
      "Train Epoch: 0 [30720/60000 (51%)]\tLoss: 0.255247\n",
      "Train Epoch: 0 [31680/60000 (53%)]\tLoss: 0.140800\n",
      "Train Epoch: 0 [32640/60000 (54%)]\tLoss: 0.154186\n",
      "Train Epoch: 0 [33600/60000 (56%)]\tLoss: 0.185621\n",
      "Train Epoch: 0 [34560/60000 (58%)]\tLoss: 0.005727\n",
      "Train Epoch: 0 [35520/60000 (59%)]\tLoss: 0.211540\n",
      "Train Epoch: 0 [36480/60000 (61%)]\tLoss: 0.097532\n",
      "Train Epoch: 0 [37440/60000 (62%)]\tLoss: 0.052581\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.101422\n",
      "Train Epoch: 0 [39360/60000 (66%)]\tLoss: 0.036912\n",
      "Train Epoch: 0 [40320/60000 (67%)]\tLoss: 0.153642\n",
      "Train Epoch: 0 [41280/60000 (69%)]\tLoss: 0.087825\n",
      "Train Epoch: 0 [42240/60000 (70%)]\tLoss: 0.015373\n",
      "Train Epoch: 0 [43200/60000 (72%)]\tLoss: 0.065247\n",
      "Train Epoch: 0 [44160/60000 (74%)]\tLoss: 0.042352\n",
      "Train Epoch: 0 [45120/60000 (75%)]\tLoss: 0.009997\n",
      "Train Epoch: 0 [46080/60000 (77%)]\tLoss: 0.076556\n",
      "Train Epoch: 0 [47040/60000 (78%)]\tLoss: 0.022311\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.264837\n",
      "Train Epoch: 0 [48960/60000 (82%)]\tLoss: 0.074817\n",
      "Train Epoch: 0 [49920/60000 (83%)]\tLoss: 0.010214\n",
      "Train Epoch: 0 [50880/60000 (85%)]\tLoss: 0.047293\n",
      "Train Epoch: 0 [51840/60000 (86%)]\tLoss: 0.057325\n",
      "Train Epoch: 0 [52800/60000 (88%)]\tLoss: 0.022254\n",
      "Train Epoch: 0 [53760/60000 (90%)]\tLoss: 0.015652\n",
      "Train Epoch: 0 [54720/60000 (91%)]\tLoss: 0.139571\n",
      "Train Epoch: 0 [55680/60000 (93%)]\tLoss: 0.013566\n",
      "Train Epoch: 0 [56640/60000 (94%)]\tLoss: 0.076922\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.137473\n",
      "Train Epoch: 0 [58560/60000 (98%)]\tLoss: 0.006741\n",
      "Train Epoch: 0 [59520/60000 (99%)]\tLoss: 0.023839\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.285609\n",
      "Train Epoch: 1 [960/60000 (2%)]\tLoss: 0.050044\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 0.001852\n",
      "Train Epoch: 1 [2880/60000 (5%)]\tLoss: 0.015107\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.209175\n",
      "Train Epoch: 1 [4800/60000 (8%)]\tLoss: 0.096749\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.134809\n",
      "Train Epoch: 1 [6720/60000 (11%)]\tLoss: 0.006257\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.005635\n",
      "Train Epoch: 1 [8640/60000 (14%)]\tLoss: 0.053820\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.153804\n",
      "Train Epoch: 1 [10560/60000 (18%)]\tLoss: 0.135170\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.003912\n",
      "Train Epoch: 1 [12480/60000 (21%)]\tLoss: 0.068506\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.075347\n",
      "Train Epoch: 1 [14400/60000 (24%)]\tLoss: 0.009653\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.110741\n",
      "Train Epoch: 1 [16320/60000 (27%)]\tLoss: 0.038350\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.066500\n",
      "Train Epoch: 1 [18240/60000 (30%)]\tLoss: 0.057576\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.064597\n",
      "Train Epoch: 1 [20160/60000 (34%)]\tLoss: 0.000587\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.328133\n",
      "Train Epoch: 1 [22080/60000 (37%)]\tLoss: 0.004594\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.282138\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.015925\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.018561\n",
      "Train Epoch: 1 [25920/60000 (43%)]\tLoss: 0.020007\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.001713\n",
      "Train Epoch: 1 [27840/60000 (46%)]\tLoss: 0.007703\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.003559\n",
      "Train Epoch: 1 [29760/60000 (50%)]\tLoss: 0.063066\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.008523\n",
      "Train Epoch: 1 [31680/60000 (53%)]\tLoss: 0.081484\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.001433\n",
      "Train Epoch: 1 [33600/60000 (56%)]\tLoss: 0.022505\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.199411\n",
      "Train Epoch: 1 [35520/60000 (59%)]\tLoss: 0.011483\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.101824\n",
      "Train Epoch: 1 [37440/60000 (62%)]\tLoss: 0.124378\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.022181\n",
      "Train Epoch: 1 [39360/60000 (66%)]\tLoss: 0.008452\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.003470\n",
      "Train Epoch: 1 [41280/60000 (69%)]\tLoss: 0.004801\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.007002\n",
      "Train Epoch: 1 [43200/60000 (72%)]\tLoss: 0.006766\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.116482\n",
      "Train Epoch: 1 [45120/60000 (75%)]\tLoss: 0.018092\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.084995\n",
      "Train Epoch: 1 [47040/60000 (78%)]\tLoss: 0.001964\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.007371\n",
      "Train Epoch: 1 [48960/60000 (82%)]\tLoss: 0.075687\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.013054\n",
      "Train Epoch: 1 [50880/60000 (85%)]\tLoss: 0.473017\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.177598\n",
      "Train Epoch: 1 [52800/60000 (88%)]\tLoss: 0.040893\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.133782\n",
      "Train Epoch: 1 [54720/60000 (91%)]\tLoss: 0.141572\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.066210\n",
      "Train Epoch: 1 [56640/60000 (94%)]\tLoss: 0.174737\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.148726\n",
      "Train Epoch: 1 [58560/60000 (98%)]\tLoss: 0.101968\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.001737\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.075144\n",
      "Train Epoch: 2 [960/60000 (2%)]\tLoss: 0.031893\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.154648\n",
      "Train Epoch: 2 [2880/60000 (5%)]\tLoss: 0.003588\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.004369\n",
      "Train Epoch: 2 [4800/60000 (8%)]\tLoss: 0.221044\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.052596\n",
      "Train Epoch: 2 [6720/60000 (11%)]\tLoss: 0.003282\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.017222\n",
      "Train Epoch: 2 [8640/60000 (14%)]\tLoss: 0.016261\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.121589\n",
      "Train Epoch: 2 [10560/60000 (18%)]\tLoss: 0.109742\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.112559\n",
      "Train Epoch: 2 [12480/60000 (21%)]\tLoss: 0.046196\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.001442\n",
      "Train Epoch: 2 [14400/60000 (24%)]\tLoss: 0.343551\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.017271\n",
      "Train Epoch: 2 [16320/60000 (27%)]\tLoss: 0.050793\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.103837\n",
      "Train Epoch: 2 [18240/60000 (30%)]\tLoss: 0.090433\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.057920\n",
      "Train Epoch: 2 [20160/60000 (34%)]\tLoss: 0.001304\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.004665\n",
      "Train Epoch: 2 [22080/60000 (37%)]\tLoss: 0.000704\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.068080\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.069542\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.138820\n",
      "Train Epoch: 2 [25920/60000 (43%)]\tLoss: 0.015459\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.039079\n",
      "Train Epoch: 2 [27840/60000 (46%)]\tLoss: 0.002859\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.010750\n",
      "Train Epoch: 2 [29760/60000 (50%)]\tLoss: 0.004953\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.020392\n",
      "Train Epoch: 2 [31680/60000 (53%)]\tLoss: 0.004576\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.047593\n",
      "Train Epoch: 2 [33600/60000 (56%)]\tLoss: 0.083233\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.024955\n",
      "Train Epoch: 2 [35520/60000 (59%)]\tLoss: 0.073862\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.076192\n",
      "Train Epoch: 2 [37440/60000 (62%)]\tLoss: 0.005926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.008462\n",
      "Train Epoch: 2 [39360/60000 (66%)]\tLoss: 0.007019\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.004832\n",
      "Train Epoch: 2 [41280/60000 (69%)]\tLoss: 0.001490\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.083694\n",
      "Train Epoch: 2 [43200/60000 (72%)]\tLoss: 0.051694\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.065394\n",
      "Train Epoch: 2 [45120/60000 (75%)]\tLoss: 0.034876\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.229529\n",
      "Train Epoch: 2 [47040/60000 (78%)]\tLoss: 0.004914\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.037459\n",
      "Train Epoch: 2 [48960/60000 (82%)]\tLoss: 0.015111\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.007198\n",
      "Train Epoch: 2 [50880/60000 (85%)]\tLoss: 0.025517\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.117649\n",
      "Train Epoch: 2 [52800/60000 (88%)]\tLoss: 0.018628\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.001531\n",
      "Train Epoch: 2 [54720/60000 (91%)]\tLoss: 0.009859\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.000747\n",
      "Train Epoch: 2 [56640/60000 (94%)]\tLoss: 0.014148\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.007758\n",
      "Train Epoch: 2 [58560/60000 (98%)]\tLoss: 0.000329\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.009865\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.038981\n",
      "Train Epoch: 3 [960/60000 (2%)]\tLoss: 0.003681\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.002450\n",
      "Train Epoch: 3 [2880/60000 (5%)]\tLoss: 0.015577\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.002504\n",
      "Train Epoch: 3 [4800/60000 (8%)]\tLoss: 0.003175\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.171947\n",
      "Train Epoch: 3 [6720/60000 (11%)]\tLoss: 0.005934\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.001390\n",
      "Train Epoch: 3 [8640/60000 (14%)]\tLoss: 0.004317\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.000902\n",
      "Train Epoch: 3 [10560/60000 (18%)]\tLoss: 0.002908\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.046224\n",
      "Train Epoch: 3 [12480/60000 (21%)]\tLoss: 0.021250\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.029493\n",
      "Train Epoch: 3 [14400/60000 (24%)]\tLoss: 0.009990\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.056485\n",
      "Train Epoch: 3 [16320/60000 (27%)]\tLoss: 0.001455\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.416101\n",
      "Train Epoch: 3 [18240/60000 (30%)]\tLoss: 0.002676\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.000490\n",
      "Train Epoch: 3 [20160/60000 (34%)]\tLoss: 0.003835\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.006864\n",
      "Train Epoch: 3 [22080/60000 (37%)]\tLoss: 0.036837\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.034931\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.002447\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.000117\n",
      "Train Epoch: 3 [25920/60000 (43%)]\tLoss: 0.003860\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.015056\n",
      "Train Epoch: 3 [27840/60000 (46%)]\tLoss: 0.048345\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.000862\n",
      "Train Epoch: 3 [29760/60000 (50%)]\tLoss: 0.001029\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.409685\n",
      "Train Epoch: 3 [31680/60000 (53%)]\tLoss: 0.039978\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.000503\n",
      "Train Epoch: 3 [33600/60000 (56%)]\tLoss: 0.012680\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.003054\n",
      "Train Epoch: 3 [35520/60000 (59%)]\tLoss: 0.001441\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.010611\n",
      "Train Epoch: 3 [37440/60000 (62%)]\tLoss: 0.007675\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.031825\n",
      "Train Epoch: 3 [39360/60000 (66%)]\tLoss: 0.001748\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.001672\n",
      "Train Epoch: 3 [41280/60000 (69%)]\tLoss: 0.006502\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.080272\n",
      "Train Epoch: 3 [43200/60000 (72%)]\tLoss: 0.192489\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.025733\n",
      "Train Epoch: 3 [45120/60000 (75%)]\tLoss: 0.004255\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.103858\n",
      "Train Epoch: 3 [47040/60000 (78%)]\tLoss: 0.095913\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.047807\n",
      "Train Epoch: 3 [48960/60000 (82%)]\tLoss: 0.051629\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.115905\n",
      "Train Epoch: 3 [50880/60000 (85%)]\tLoss: 0.009953\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.028912\n",
      "Train Epoch: 3 [52800/60000 (88%)]\tLoss: 0.009210\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.005367\n",
      "Train Epoch: 3 [54720/60000 (91%)]\tLoss: 0.090283\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.010485\n",
      "Train Epoch: 3 [56640/60000 (94%)]\tLoss: 0.003275\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.015680\n",
      "Train Epoch: 3 [58560/60000 (98%)]\tLoss: 0.010856\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.000409\n"
     ]
    }
   ],
   "source": [
    "#training our model\n",
    "train(4,0.5,cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f643d2aca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting the curve relation how our loss drops , at the end the spikes may be due to accumulated momentum\n",
    "plt.plot(lr_list,loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the test function of our model\n",
    "def test(arch):\n",
    "    arch.eval()\n",
    "    test_loss = 0\n",
    "    accurate_pred = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = arch.forward(data)  #forward pass for test set\n",
    "        # sum up batch loss\n",
    "        test_loss += nn.functional.nll_loss(output, target, size_average=False).data[0]\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        accurate_pred += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, accurate_pred, len(test_loader.dataset),\n",
    "        100. * accurate_pred / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0357, Accuracy: 9888/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#printing the accuracy and loss of test set and also the number of classes classified correctly by the model\n",
    "test(cnn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
